# ğŸƒâ€â™‚ï¸ Plank Exercise Correction AI

An AI-powered system that analyzes plank form in real-time using computer vision and provides instant feedback for perfect technique. ğŸ¯

## âœ¨ Features

- **ğŸ“¹ Real-time pose analysis** through webcam
- **ğŸ” Intelligent form correction** using pose detection
- **âš¡ Instant feedback** on technique accuracy
- **ğŸ¯ Three-class classification** (Correct, High Hips, Low Hips)
- **ğŸ“Š Confidence scoring** for form assessment
- **ğŸ”§ Smoothing & debouncing** for stable feedback
- **ğŸ“ˆ Visual progress indicators** and feedback display

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install opencv-python mediapipe pandas numpy scikit-learn matplotlib seaborn onnx onnxruntime xgboost tqdm
```

### Usage Steps
1. **ğŸ“š Training Pipeline** - Run notebooks 1-4 in sequence to train the model
2. **ğŸ‹ï¸ Live Exercise** - Use notebook 5 for real-time form correction
3. **ğŸ“¸ Camera Setup** - Position yourself sideways to webcam showing full body profile
4. **ğŸ® Controls** - Press 'q' to quit the application

> **ğŸ’¡ Pro Tip:** Ensure good lighting and clear background for optimal pose detection

## ğŸ““ Notebook Workflow

| Order | Notebook | Purpose | Description |
|-------|----------|---------|-------------|
| 1ï¸âƒ£ | `1_exploratory_data_analysis.ipynb` | ğŸ“Š **Data Analysis** | Analyze landmark data and pose distributions |
| 2ï¸âƒ£ | `2_data_preprocessing_and_model_training.ipynb` | ğŸ¤– **Model Training** | Feature extraction, pipeline creation, ML training |
| 3ï¸âƒ£ | `3_model_inference.ipynb` | ğŸ§ª **Model Testing** | Performance evaluation with detailed metrics |
| 4ï¸âƒ£ | `4_deploy.ipynb` | ğŸš€ **Model Deployment** | Convert to ONNX format for optimization |
| 5ï¸âƒ£ | `5_live_camera_detection.ipynb` | **ğŸ‹ï¸ Live Application** | **Main app - Start here for exercise!** |

## ğŸ® User Interface

### Visual Feedback
- **ğŸŸ¢ Green text** â†’ Correct form âœ…
- **ğŸ”´ Red text** â†’ High hips detected âš ï¸
- **ğŸŸ  Orange text** â†’ Low hips detected âš ï¸
- **ğŸŸ¡ Yellow text** â†’ Analyzing/Adjusting ğŸ”„
- **ğŸ“Š Confidence score** â†’ Model certainty display
- **ğŸ¯ Real-time status** â†’ Live form assessment

### Controls
- **'q'** â†’ Quit application âŒ

## ğŸ§  Technical Overview

### AI Architecture
The system uses **MediaPipe** for pose detection and extracts key biomechanical features:

- **ğŸ’ª Elbow angles** - Arm positioning and stability
- **ğŸƒ Shoulder angles** - Upper body alignment  
- **ğŸ¦´ Hip angles** - Core engagement assessment
- **ğŸ¦µ Knee angles** - Lower body positioning
- **ğŸ“ Body alignment** - Straight line maintenance
- **ğŸ“ Hip deviation** - Distance from optimal position
- **ğŸ“Š Geometric features** - Comprehensive form analysis (20 features total)

### Machine Learning Pipeline
A **ğŸŒ² Random Forest model** (with alternative algorithms) processes extracted features through:
- **ğŸ”§ SimpleImputer** - Handles missing landmark data
- **ğŸ“Š StandardScaler** - Feature normalization
- **ğŸ¤– Classification Model** - Form accuracy prediction

Available models: **Logistic Regression**, **KNN**, **Decision Tree**, **Random Forest**, **XGBoost**

## ğŸ“ Project Structure

```
plank/
â”œâ”€â”€ ğŸ“Š data/                    # Training datasets (train.csv, test.csv)
â”œâ”€â”€ ğŸ¤– models/                  # Trained AI models
â”‚   â”œâ”€â”€ pkl/                   # Scikit-learn models (.pkl files)
â”‚   â””â”€â”€ onnx/                  # Optimized deployment models (.onnx files)
â”œâ”€â”€ ğŸ““ notebooks/              # Jupyter notebooks (main workflow)
â””â”€â”€ ğŸ“– README.md               # Project documentation
```

## ğŸ‹ï¸ Exercise Guidelines

### âœ… Correct Plank Form
- Start in push-up position ğŸ¤²
- Forearms on ground, elbows under shoulders ğŸ’ª
- Body forms straight line: head â†’ shoulders â†’ hips â†’ ankles ğŸ“
- Engage core muscles ğŸ”¥
- Keep hips level (not too high or low) âš–ï¸
- Maintain neutral spine ğŸ¦´
- Breathe steadily ğŸ«

### âŒ Common Mistakes Detected
- **ğŸ”´ High Hips:** Hips raised too high (creates inverted V) ğŸš«
- **ğŸŸ  Low Hips:** Hips sagging too low (back arches) ğŸš«  
- **âš ï¸ Poor alignment:** Body not maintaining straight line ğŸš«

## ğŸ”§ Configuration Options

### Detection Settings
```python
VISIBILITY_THRESHOLD = 0.5        # Landmark visibility requirement
SMOOTHING_WINDOW_SIZE = 7         # Prediction smoothing
STATUS_HISTORY_LENGTH = 10        # Status consistency checking
STATUS_COOLDOWN_SEC = 0.5         # Minimum time between status changes
CONFIDENCE_THRESHOLD_CORRECT = 0.65   # Confidence for "correct" display
CONFIDENCE_THRESHOLD_WRONG = 0.50     # Confidence for error display
```

### Model Selection
Change `MODEL_KEY` in notebooks to use different algorithms:
- **'RF'** - Random Forest (default, best performance)
- **'XGB'** - XGBoost (gradient boosting)
- **'LR'** - Logistic Regression (linear model)
- **'KNN'** - K-Nearest Neighbors (similarity-based)
- **'DT'** - Decision Tree (rule-based)

## ğŸ”§ Troubleshooting

### Camera Issues
- **ğŸ“¹ No detection:** Check webcam permissions and lighting
- **ğŸ–¼ï¸ Poor tracking:** Ensure clear background and full body visibility
- **ğŸ‘¤ Position:** Position sideways to camera for optimal profile view
- **ğŸ’¡ Lighting:** Bright, even lighting improves detection accuracy

### Model Performance
- **ğŸ¤– Retraining:** Run notebook 2 with different `CHOSEN_MODEL_KEY`
- **âš™ï¸ Algorithm:** Try different models (RF recommended for best results)
- **ğŸ”„ Data:** Check for sufficient training data quality
- **ğŸ“Š Thresholds:** Adjust confidence thresholds for sensitivity

### Environment Setup
- **ğŸ“¦ Dependencies:** Verify all packages are correctly installed
- **ğŸ” Permissions:** Ensure camera access is granted
- **ğŸ–¥ï¸ Resources:** Monitor CPU usage during live detection
- **ğŸš€ ONNX:** Use ONNX models for faster inference

## ğŸš€ Advanced Configuration

### Feature Engineering
The system extracts **20 geometric features** from pose landmarks:
- Joint angles (elbows, shoulders, hips, knees)
- Body alignment angles
- Hip deviation measurements
- Vertical position differences
- Segment length calculations

### Performance Optimization
- **ONNX Runtime** for 3x faster inference
- **Prediction smoothing** reduces jittery feedback
- **Status debouncing** prevents rapid status changes
- **Visibility filtering** ensures reliable landmark data

### Training Process
1. **ğŸ“Š EDA** â†’ Understand data distribution and quality
2. **ğŸ”§ Preprocessing** â†’ Feature extraction with GeometryUtils
3. **ğŸ¤– Pipeline Creation** â†’ Imputation + Scaling + Model
4. **ğŸ“ˆ Training** â†’ Multiple algorithms with balanced classes
5. **ğŸ“Š Evaluation** â†’ Classification reports and confusion matrices
6. **ğŸš€ Deployment** â†’ ONNX conversion for production use

---

**ğŸ‰ Ready to perfect your planks?** Open `5_live_camera_detection.ipynb` and start training! ğŸƒâ€â™‚ï¸âœ¨

**â“ Need help?** Check individual notebook comments for detailed explanations. ğŸ“š

---

*Built with MediaPipe, scikit-learn, and ONNX Runtime for real-time exercise form correction* ğŸ¤–
